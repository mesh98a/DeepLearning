{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mesh98a/DeepLearning/blob/main/labN3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lcJMZ3ObvOE",
    "outputId": "df993e07-48be-4a11-b3e0-c1e96e6396a9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5ovgd4kwNko"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical, plot_model, image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Rescaling\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoGUMiCTmRsb"
   },
   "source": [
    "downloading archive with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_4JUVJPkSRh",
    "outputId": "564dcc49-25b0-49dd-e327-3e7c245227ee"
   },
   "outputs": [],
   "source": [
    "!wget -O images.zip \"https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip?download=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wE8pwP_LmP_U"
   },
   "outputs": [],
   "source": [
    "!mkdir -p cnn\n",
    "!mkdir -p cnn/images\n",
    "!unzip -qq images.zip -d cnn/images\n",
    "!tar -xzf cnn/images/caltech-101/101_ObjectCategories.tar.gz -C cnn/images\n",
    "#removing temp folder __MACOS**\n",
    "!rm -rf cnn/images/__**\n",
    "!rm -rf cnn/images/caltech-101 # && rmdir cnn/images/caltech-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmjdAq4dgeAv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Source and destination paths\n",
    "src_base = 'cnn/images/101_ObjectCategories'\n",
    "dst_base = 'cnn/5_classes'\n",
    "\n",
    "# Create destination directory\n",
    "os.makedirs(dst_base, exist_ok=True)\n",
    "\n",
    "# List of desired classes\n",
    "selected_classes = ['watch', 'bonsai', 'kangaroo', 'brain', 'ketch']\n",
    "\n",
    "# Copy the folders of the selected classes\n",
    "for cls in selected_classes:\n",
    "    src_path = os.path.join(src_base, cls)\n",
    "    dst_path = os.path.join(dst_base, cls)\n",
    "    if os.path.exists(src_path):\n",
    "      if os.path.exists(dst_path):\n",
    "        shutil.rmtree(dst_path)\n",
    "      shutil.copytree(src_path, dst_path)\n",
    "    else:\n",
    "        print(f\"Class {cls} was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASHF0a59jjhP",
    "outputId": "885cfcdb-095d-40dd-9cac-4886d9cb8a64"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path('cnn/5_classes').with_suffix('')\n",
    "\n",
    "image_count = len(list(data_dir.glob('**/*.jpg')))\n",
    "print(f'Images: {image_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZi877YKE7lJ"
   },
   "source": [
    "Let's find the smallest dimensions. In the future, I plan to use this to normalize the size of images, because for the network we need data with the same resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-267HGbqlzw",
    "outputId": "c6bfbd13-be42-40aa-b83e-682130ec37a9"
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "images = [PIL.Image.open(str(image)) for image in list(data_dir.glob('*/*'))]\n",
    "\n",
    "\n",
    "heights = [i.height for i in images ]\n",
    "widths = [i.width for i in images ]\n",
    "\n",
    "min_height = min(heights)\n",
    "min_width = min(widths)\n",
    "print(f'Minimal height {min_height}')\n",
    "print(f'Minimal width {min_width}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8bJ-_xXrZjR"
   },
   "source": [
    "Visualize several images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "z3YR4Ynsr04Z",
    "outputId": "fa9fd2ce-dc86-4cd0-f429-1c7fab3e7664"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(images[100])\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(images[200])\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRO2rJROyZd0"
   },
   "source": [
    "# **Data Preproccesing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuUFb3ppF2xb"
   },
   "source": [
    ".unbatch() Breaks the batches into individual (image, label) pairs.\n",
    "After this, the dataset yields one image and one label at a time instead of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XCbUFrtt9RO",
    "outputId": "21bb7762-2f5e-4c78-c5f1-ddebb8561779"
   },
   "outputs": [],
   "source": [
    "# https://massedcompute.com/faq-answers/?question=What%20is%20the%20optimal%20image%20size%20for%20training%20a%20CNN%20model%20for%20image%20recognition?\n",
    "min_height = 197\n",
    "min_width = 300\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',                # Automatically infer labels from subdirectory names\n",
    "    label_mode='int',                 # Labels are returned as integers\n",
    "    image_size=(min_height, min_width),  # Resize images to 224x224\n",
    "    batch_size=85,                    # Load images in batches\n",
    "    shuffle=True                      # Shuffle the dataset\n",
    ").unbatch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "EMKQFQ09GZoN",
    "outputId": "526adbec-6035-4761-f09c-90dcd7549509"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "i = 1\n",
    "for image, label in dataset.take(9):  # Take the first 9 images from the dataset\n",
    "    plt.subplot(3, 3, i)  # Create a 3x3 grid of subplots\n",
    "    i += 1\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))  # Convert tensor to NumPy and display the image\n",
    "    plt.title(f\"Label: {label}\")  # Show the label as the title\n",
    "    plt.axis(\"off\")  # Hide the axes for a cleaner look\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXlMj_xRuUG9",
    "outputId": "a83ac2c0-e394-4c8e-9b23-18c1a692cdbd"
   },
   "outputs": [],
   "source": [
    "train_ds = dataset.take(400)\n",
    "val_ds = dataset.skip(400).take(100)\n",
    "test_ds = dataset.skip(500)\n",
    "\n",
    "print(f'Train: {train_ds.reduce(0, lambda x, _: x + 1)}')\n",
    "print(f'Val: {val_ds.reduce(0, lambda x, _: x + 1)}')\n",
    "print(f'Test: {test_ds.reduce(0, lambda x, _: x + 1)}')\n",
    "\n",
    "train_ds = train_ds.batch(50)\n",
    "val_ds = val_ds.batch(50)\n",
    "test_ds = test_ds.batch(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6In8PvAt91h"
   },
   "source": [
    "# Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JD6SW19Wqq9"
   },
   "source": [
    "Plain 3-layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 947
    },
    "id": "XFp-Qjop0CkU",
    "outputId": "f5389f17-0d8a-40be-d027-97308b5e8fce"
   },
   "outputs": [],
   "source": [
    "def buil_model(input_shape=(197, 300, 3), num_classes=5):\n",
    "  input_tensor = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "  x = Rescaling(1./255)(input_tensor)\n",
    "  x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "  x = MaxPooling2D(2,2)(x)\n",
    "  x = Conv2D(64, (3,3), 1, activation='relu')(x)\n",
    "  x = MaxPooling2D(2,2)(x)\n",
    "  x = Conv2D(128, (3,3), 1, activation='relu')(x)\n",
    "  x = MaxPooling2D(2,2)(x)\n",
    "\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(64, activation='relu')(x)\n",
    "  output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "  model.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "model = buil_model()\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKvNIsjw23AB"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data):\n",
    "    true_labels = []           # To store the actual labels from the test data\n",
    "    predicted_labels = []      # To store the predicted class indices\n",
    "    predicted_proba = []       # To store the predicted class probabilities (confidence)\n",
    "    predictions_full = []      # To store the full prediction vectors (all class probabilities)\n",
    "\n",
    "    for images, labels in test_data:\n",
    "        predictions = model.predict(images)  # Get prediction probabilities from the model\n",
    "        predicted_classes = np.argmax(predictions, axis=1)  # Get predicted class index (highest probability)\n",
    "        predicted_probabilities = np.max(predictions, axis=1)  # Get max probability for each prediction\n",
    "\n",
    "        true_labels.extend(labels.numpy())  # Add true labels to the list\n",
    "        predicted_labels.extend(predicted_classes)  # Add predicted labels to the list\n",
    "        predicted_proba.extend(predicted_probabilities)  # Add predicted confidences\n",
    "        predictions_full.extend(predictions)  # Add full prediction vectors\n",
    "\n",
    "    return true_labels, predicted_labels, predicted_proba, predictions_full\n",
    "\n",
    "# ConfusionMatrix\n",
    "def print_report(true_labels, predicted_labels, predicted_proba):\n",
    "    report = classification_report(true_labels, predicted_labels)\n",
    "    print(report)\n",
    "    cn = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(true_labels, predicted_labels))\n",
    "    cn.plot()\n",
    "\n",
    "def learning_curves(history):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiclass_roc(true_labels, predicted_scores, title='ROC Curves for All Classes'):\n",
    "\n",
    "    y_test = np.array(true_labels)\n",
    "    y_score = np.array(predicted_scores)\n",
    "\n",
    "    n_classes = y_score.shape[1]\n",
    "    classes = list(range(n_classes))\n",
    "\n",
    "    # Binarize labels for one-vs-rest comparison\n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = plt.cm.get_cmap(\"tab10\", n_classes)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc:.2f})', color=colors(i))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_multiclass_precision_recall(true_labels, predicted_scores, title='Precision-Recall Curves (AUC-PR) for All Classes'):\n",
    "\n",
    "    y_test = np.array(true_labels)\n",
    "    y_score = np.array(predicted_scores)\n",
    "\n",
    "    n_classes = y_score.shape[1]\n",
    "    classes = list(range(n_classes))\n",
    "\n",
    "    # Binarize labels for one-vs-rest comparison\n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = plt.cm.get_cmap(\"tab10\", n_classes)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        ap_score = average_precision_score(y_test_bin[:, i], y_score[:, i])\n",
    "        plt.plot(recall, precision, lw=2,\n",
    "                 label=f'Class {i} (AP = {ap_score:.2f})',\n",
    "                 color=colors(i))\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_top1_error(true_labels, predicted_scores):\n",
    "    y_test = np.array(true_labels)\n",
    "    y_score = np.array(predicted_scores)\n",
    "\n",
    "    y_pred = np.argmax(y_score, axis=1)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    top1_error = (1 - acc) * 100\n",
    "    print(f\"Top-1 Error Rate: {top1_error:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS5w3Uer5GLH"
   },
   "source": [
    "**RESULTS for Plain 3-layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "I-8s5SVL3NfH",
    "outputId": "1c0392ab-9ec8-4c73-c1b0-77d77333c812"
   },
   "outputs": [],
   "source": [
    "true_labels, predicted_labels, predicted_proba,predictions_full = evaluate_model(model, test_ds)\n",
    "print_report(true_labels, predicted_labels, predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GcCnk7Kt4wFH",
    "outputId": "e7b6e56a-319d-4896-ddac-0fdece7906c5"
   },
   "outputs": [],
   "source": [
    "learning_curves(history)\n",
    "plot_multiclass_roc(true_labels, predictions_full)\n",
    "plot_multiclass_precision_recall(true_labels, predictions_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOutPl6r46YB",
    "outputId": "e5da3ca5-e9af-4bdd-9c32-cf33ca12ae01"
   },
   "outputs": [],
   "source": [
    "print_top1_error(true_labels, predictions_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmIxiGNVoLI9"
   },
   "source": [
    "# **Frozen pre-trained ResNet as feature extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "1Ffmlzl65qEt",
    "outputId": "f81c6be5-1249-44e2-9465-1c516837483d"
   },
   "outputs": [],
   "source": [
    "def preprocess_batch(image, label):\n",
    "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "train_ds_resnet_frozen = train_ds.map(preprocess_batch)\n",
    "val_ds_resnet_frozen = val_ds.map(preprocess_batch)\n",
    "test_ds_resnet_frozen = test_ds.map(preprocess_batch)\n",
    "\n",
    "input_shape = (197, 300, 3)\n",
    "num_classes = 5\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model_resnet_frozen = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model_resnet_frozen.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_resnet_frozen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pM2UNzcwY-NV",
    "outputId": "54a28d37-dbbd-422c-af46-3c955c94c06d"
   },
   "outputs": [],
   "source": [
    "\n",
    "history_resnet_frozen = model_resnet_frozen.fit(\n",
    "    train_ds_resnet_frozen,\n",
    "    epochs=5,\n",
    "    validation_data=val_ds_resnet_frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "U6VEpPUd72Cs",
    "outputId": "24f5f291-98ce-44b8-90fd-c8c8e292399f"
   },
   "outputs": [],
   "source": [
    "true_labels2, predicted_labels2, predicted_proba2,predictions_full2 = evaluate_model(model, test_ds_resnet_frozen)\n",
    "print_report(true_labels2, predicted_labels2, predicted_proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "shTpU8s08KVi",
    "outputId": "b979bf41-12fa-4fb9-a13b-b8078b0ba901"
   },
   "outputs": [],
   "source": [
    "learning_curves(history_resnet_frozen)\n",
    "plot_multiclass_roc(true_labels2, predictions_full2)\n",
    "plot_multiclass_precision_recall(true_labels2, predictions_full2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-e-6lmPGUdh",
    "outputId": "f5cbd4f6-b894-4f86-935c-53c8718c560a"
   },
   "outputs": [],
   "source": [
    "print_top1_error(true_labels, predictions_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65szPZAozXz_"
   },
   "source": [
    "# **Fine-tuned pre-trained ResNet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zs3i3VRw2rVP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "cZRaSiFLGmlr",
    "outputId": "b2905976-5846-4abb-f8de-8c396b187e3a"
   },
   "outputs": [],
   "source": [
    "def preprocess_batch(image, label):\n",
    "    image = tf.keras.applications.resnet.preprocess_input(image)  # ResNet expects this preprocessing\n",
    "    return image, label\n",
    "train_ds_resnet = train_ds.map(preprocess_batch)\n",
    "test_ds_resnet = test_ds.map(preprocess_batch)\n",
    "val_ds_resnet = val_ds.map(preprocess_batch)\n",
    "\n",
    "input_shape = (197, 300, 3)\n",
    "num_classes = 5\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model_resnet= tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_resnet.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9bxvhxbjPBo",
    "outputId": "01998564-135a-42e2-91e9-51cbe13d57c2"
   },
   "outputs": [],
   "source": [
    "history_resnet = model_resnet.fit(\n",
    "    train_ds_resnet,\n",
    "    epochs=3,\n",
    "    validation_data=val_ds_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "WJirh-alzPzM",
    "outputId": "4ac53450-344a-4e8f-fc04-36e0bd97a045"
   },
   "outputs": [],
   "source": [
    "model_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4-lPDTvISFx",
    "outputId": "93f4f867-113a-4033-efd5-a4d03b0928ba"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "model_resnet.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fine-tuning!\n",
    "model_resnet.fit(train_ds_resnet, validation_data=val_ds_resnet, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "id": "AgwXRT7xIjOc",
    "outputId": "6e4b383c-8050-4d50-bab5-ac1a65b1ef73"
   },
   "outputs": [],
   "source": [
    "true_labels3, predicted_labels3, predicted_proba3,predictions_full3 = evaluate_model(model_resnet, test_ds_resnet)\n",
    "print_report(true_labels3, predicted_labels3, predicted_proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "h0zxJFlNItqI",
    "outputId": "1813c91b-75f7-42ea-d64c-aaac42d44766"
   },
   "outputs": [],
   "source": [
    "learning_curves(history_resnet)\n",
    "plot_multiclass_roc(true_labels3, predictions_full3)\n",
    "plot_multiclass_precision_recall(true_labels3, predictions_full3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEfHTuiLsMkB"
   },
   "source": [
    "# Visualize filters and corresponding feature maps of the first and second Conv2d layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VsZsYkwFo-9B",
    "outputId": "0353675b-933f-4b73-f442-db472f5352ab"
   },
   "outputs": [],
   "source": [
    "def print_filters(filters, title, n=6, channel=0):\n",
    "    print(f'\\n {title}')\n",
    "    for i in range(n):\n",
    "        f = filters[:, :, channel, i]\n",
    "        print(f\"\\nFilter #{i}:\")\n",
    "        print(np.round(f, 3))\n",
    "\n",
    "def visualize_filters(filters, title, n=6, channel=0):\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n * 2, 2))\n",
    "    for i in range(n):\n",
    "        f = filters[:, :, channel, i]\n",
    "        axes[i].imshow(f, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Get Conv2D layers\n",
    "conv_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
    "\n",
    "# Visualize filters of the 1st and 2nd Conv2D layers\n",
    "filters1, _ = conv_layers[0].get_weights()\n",
    "filters2, _ = conv_layers[1].get_weights()\n",
    "\n",
    "# Print some filters to view them numerically\n",
    "print_filters(filters1, 'First 6 filters of the 1st Conv2D layer', 6)\n",
    "print_filters(filters2, 'First 6 filters of the 2nd Conv2D layer', 6)\n",
    "\n",
    "# Visualize as grayscale images (higher values appear darker)\n",
    "visualize_filters(filters1, 'First 6 filters of the 1st Conv2D layer', 6)\n",
    "visualize_filters(filters2, 'First 6 filters of the 2nd Conv2D layer', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxz025_VsnH2"
   },
   "source": [
    "**a)**\n",
    "1st layer) The filters appear to have captured basic visual patterns, such as edges, contrast changes, and texture information.Some filters capture horizontal or vertical lines, while others detect color-specific regions.\n",
    "\n",
    "2st layer) These filters extract more complex patterns, such as shapes or combinations of edges. They seem to build upon the features from the 1st layer to identify higher-level abstractions\n",
    "\n",
    "**b)**\n",
    "Yes. In Layer 2, a few filters appear nearly entirely black or uniformly dark. I think I have too little data.\n",
    "\n",
    "**c)**\n",
    "Yes, based on the activation maps, some filters clearly activate in background regions (trees, water, sky).\n",
    "\n",
    "**d)** Yes, the model is controlled by RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "gxKLRREdYaF9",
    "outputId": "aa1a3b2a-6d49-4d93-acc6-0466ea2fc23a"
   },
   "outputs": [],
   "source": [
    "# Pfad zum konkreten Bild\n",
    "#img_path = \"/content/cnn/5_classes/kangaroo/image_0008.jpg\"\n",
    "#img = image.load_img(img_path, target_size=(197, 300))  # Passe target_size an dein Modell an\n",
    "#img_array = image.img_to_array(img)\n",
    "#img_array = img_array / 255.0\n",
    "image_batch, _ = next(iter(dataset.take(1)))\n",
    "input_image = np.expand_dims(image_batch, axis=0)\n",
    "\n",
    "\n",
    "conv_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
    "\n",
    "# model to get the feature maps from the first two Conv2D layers\n",
    "activation_model = tf.keras.models.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=[conv_layers[0].output, conv_layers[1].output]\n",
    ")\n",
    "\n",
    "# feature maps\n",
    "feature_maps = activation_model.predict(input_image)\n",
    "\n",
    "\n",
    "def plot_feature_maps(fmaps, title, n=6):\n",
    "    fmap = fmaps[0]\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n * 2, 2))\n",
    "    for i in range(n):\n",
    "        axes[i].imshow(fmap[:, :, i], cmap='viridis')\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_maps(feature_maps[0], \"First 6 filters of the 1st Conv2D layer\", 6)\n",
    "plot_feature_maps(feature_maps[1], \"First 6 filters of the 2st Conv2D layer\", 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqM0pIgL0sdG"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArCYSc5_1JYq"
   },
   "source": [
    "The plain 3-layer CNN already demonstrated strong performance, which I believe is due to the small dataset size of only 665 images. When comparing the fine-tuned pre-trained ResNet to the frozen pre-trained ResNet used as a feature extractor, the accuracy increased significantly—from 76% to 99%. The final model correctly classified 164 out of 165 test images.\n",
    "It can also be observed that both the fine-tuned pre-trained ResNet and the frozen pre-trained ResNet are highly prone to overfitting—even after just 2 epochs."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
